Here we'll document the computation of the AUCs and partial-AUCs of the computed networks for the Joint GRN study.


The following two functions will be used to calculate the AUC or pAUC of some prediction, respectively.

```{r message=FALSE, warning=FALSE, results='hide'}
library(ROCR)

getAUC <- function(truth, predicted){
  pred <- prediction(predicted, truth);
  auc <- performance(pred, "auc")@y.values[[1]];
  auc;
}


getpAUC <- function(truth, predicted, threshold=0.005){
  pred <- prediction(predicted, truth);
  auc <- performance(pred, "auc", fpr.stop=threshold)@y.values[[1]];
  auc;
}

```

We now want to produce 2 4D arrays to store the AUC and pAUC. The dimensions of the arrays are: network size, sample count, noise, and network construction method. We'll just loop through all of the arrangements of the variables until we've calculated the AUC and pAUC for every possible combination.

```{r}

METHODS <- c("Joint","Space", "WGCNA", "GeneNet")

resultsDir <- "../data/results-ena/"

#4D arrays
AUCs <- array(NA,dim=c(length(METHODS), length(SIZE), length(NP), length(NOISE)), dimnames=list(Method=METHODS,Size=SIZE, Samples=NP, Noise=NOISE))
pAUCs <- array(NA,dim=c(length(METHODS), length(SIZE), length(NP), length(NOISE)), dimnames=list(Method=METHODS,Size=SIZE, Samples=NP, Noise=NOISE))

for (size in SIZE){			
	for (ns in NP){				
		for (sigma in NOISE){
			results <- readRDS(paste(
				resultsDir,
				size,
				"nSamp",
				ns,
				"Sigma",
				sigma,
				".Rds",
				sep=""))
			
			truthCol <- results$Truth != 0
			
			AUCs["Joint", size, ns, sigma] <- getAUC(truthCol, results$ENA);
			pAUCs["Joint", size, ns, sigma] <- getpAUC(truthCol, results$ENA);			
						
			AUCs["WGCNA", size, ns, sigma] <- getAUC(truthCol, results$WGCNA)
			pAUCs["WGCNA", size, ns, sigma] <- getpAUC(truthCol, results$WGCNA)
			
			AUCs["GeneNet", size, ns, sigma] <- getAUC(truthCol, results$BootstrappedGenenet)
			pAUCs["GeneNet", size, ns, sigma] <- getpAUC(truthCol, results$BootstrappedGenenet)
			
			AUCs["Space", size, ns, sigma] <- getAUC(truthCol, abs(results$BootstrappedSPACE))
			pAUCs["Space", size, ns, sigma] <- getpAUC(truthCol, abs(results$BootstrappedSPACE))
						
		}
	}	
	saveRDS(AUCs, file="AUCs.Rds")
	saveRDS(pAUCs, file="pAUCs.Rds")
}
```

It's probably easiest to keep a 4D array within R for now, rather than writing a series of CSVs. We can output selected 2D tables of interest at a later point.

```{r}
saveRDS(AUCs, file="AUCs.Rds")
saveRDS(pAUCs, file="pAUCs.Rds")
```

Alternatively, we can convert the 4D matrix to a data.frame.

```{r}
aucTab <- as.data.frame.table(AUCs, responseName="AUC")
paucTab <- as.data.frame.table(pAUCs, responseName="pAUC")
```


### Visualization

We can now plot the performance on particular networks for closer inspection.

We can visualize the performance for a particular network and noise value in 2 dimensions by plotting the AUC of each method for the possible numbers of samples.

```{r}
library(lattice)
size <- SIZE[min(length(SIZE), 3)]
noise <- "0.25"
print(xyplot(Freq ~ Samples, group=Method, data=as.data.frame.table(AUCs[,size,,noise]), type="b", auto.key=list(space="right")))
```

And we can select on particular network from that graph and plot more specific information, such as the total number of identified connections vs. the number of false positives after reading in that network's results again.

```{r, fig.width=10, fig.height=6}
par(mfrow=c(1,2), mar=c(5.1, 4.1, 4.1, .6))

library(RColorBrewer)
colors <- brewer.pal(4, "Dark2")

#First plot

samples <- "200"
results <- readRDS(paste(
	resultsDir,
	size,
	"nSamp",
	samples,
	"Sigma",
	noise,
	".Rds",
	sep=""))

results$Truth <- as.integer(results$Truth != 0)

plot(0, 0, type="n", xlim=c(0,50), ylim=c(0,35), xlab="Predicted Connection Strength", ylab="False Positive Strength", main="200 Samples")
legend(0, 30, c("SPACE", "WGCNA", "GeneNet", "ENA"), col=colors, lwd=3, lty=1:4, y.intersp=1.5)


#' Plots a single line of the total identifid on the x-axis vs the
#' false positives on the y-axis.
#' @param df the data frame to use in the format of having the first column be the truth and the second column be the predictions for this method
#' @param color dictates the color of the line plotted
plotPerformance <- function(df, color=1, lty){
	#normalize to 0:1
	df[,2] <- df[,2] / max(df[,2])
	df <- df[order(df[,2], decreasing=TRUE),]
	df$FalsePos <- df[,2]
	df$FalsePos[df$Truth == 1] <- 0
	
	#Done organizing the data.frame, now can format for plotting.
	df$FalsePos <- cumsum(df$FalsePos)
	df[,2] <- cumsum(df[,2])
	lines(x=c(0,df[,2]), y=c(0,df[,3]), col=color, lwd=2, lty=lty)
}

sp <- results[,c(3,4)]
plotPerformance(sp,colors[1], 2)

wg <- results[,c(3,5)]
plotPerformance(wg,colors[2], 3)

gn <- results[,c(3,6)]
plotPerformance(gn,colors[3], 4)

ena <- results[,c(3,7)]
plotPerformance(ena,colors[4], 5)

##second plot

par(mar=c(5.1, 2.1, 4.1, 1.1))

samples <- "1000"

results <- readRDS(paste(
	resultsDir,
	size,
	"nSamp",
	samples,
	"Sigma",
	noise,
	".Rds",
	sep=""))

results$Truth <- as.integer(results$Truth != 0)

plot(0, 0, type="n", xlim=c(0,50), ylim=c(0,30), xlab="Predicted Connection Strength", ylab="", main="1,000 Samples")

sp <- results[,c(3,4)]
plotPerformance(sp,colors[1], 2)

wg <- results[,c(3,5)]
plotPerformance(wg,colors[2], 3)

gn <- results[,c(3,6)]
plotPerformance(gn,colors[3], 4)

ena <- results[,c(3,7)]
plotPerformance(ena,colors[4], 5)
```

### Rank Summary

The simplest way to analyze the relative pAUC or AUCs would just be to rank them, rather than trying to determine how "substantial" an improvement of .01 in the AUC, for instance, really is. So we can use the rank function, which will give us an order to all of the methods in which the highest ranked methods performed the best.

We could summarize these for a network size/sample size combination across all noise values, for instance. The code below does that, then further summarizes those summaries across all sample size values -- producing a 2D table showing the average rank for a method at a network size across all noise and sample size values.

AUCs are shown here.

```{r}
rankAvg <- array(dim=c(length(METHODS), length(SIZE)), dimnames=list(Method=METHODS, Size=SIZE))
for (size in SIZE){
	thisSize <- array(dim=c(length(NOISE), length(METHODS)), dimnames=list(Noise=NOISE, Method=METHODS))
	for (sigma in NOISE){
		thisSize[as.character(sigma), ] <- apply(apply(AUCs[,size,,as.character(sigma)], "Samples", function(x){rank(x,na.last="keep")}), 1, mean)
	}
	rankAvg[,size] <- apply(thisSize, 2, mean);
}
rankAvg
apply(rankAvg,2,rank)
```

And pAUCs here.

```{r}
rankpAvg <- array(dim=c(length(METHODS), length(SIZE)), dimnames=list(Method=METHODS, Size=SIZE))
for (size in SIZE){
	thisSize <- array(dim=c(length(NOISE), length(METHODS)), dimnames=list(Noise=NOISE, Method=METHODS))
	for (sigma in NOISE){
		thisSize[as.character(sigma), ] <- apply(apply(pAUCs[,size,,as.character(sigma)], "Samples", function(x){rank(x,na.last="keep")}), 1, mean)
	}
	rankpAvg[,size] <- apply(thisSize, 2, mean);
}
rankpAvg
apply(rankpAvg,2,rank)
```
